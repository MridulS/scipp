{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Audience**: Beginner.\n",
    "\n",
    "**Prerequisites**:\n",
    "Familiarity with basics of scipp.\n",
    "If you are new to scipp we recommend to walk though the [Getting Started](https://scipp.github.io/tutorials/getting-started.html) tutorial.\n",
    "\n",
    "**Objectives**:\n",
    "Develop an understanding of `scipp.Dataset` and how to use it for representing tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-D datasets and tables\n",
    "## What is a `Dataset`?\n",
    "\n",
    "If you are familiar with Pandas then you can think of scipp's `Dataset` as an equivalent to [pandas.DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).\n",
    "While `Dataset` is more general in that it supports multi-dimensional entries, we can use a dataset with 1-D entries as a table, similar to `pandas.DataFrame`.\n",
    "Pandas has a lot of more powerful and more specific functionality for processing of tabular data.\n",
    "On the other hand, scipp provides features such as support for physical units and powerful routines for binning and histogramming data (study the follow-up tutorial\n",
    "[From tabular data to binned data](https://scipp.github.io/tutorials/from-tabular-data-to-binned-data.html) for an introduction on this topic).\n",
    "Therefore the choice between Pandas and scipp depends on the application.\n",
    "\n",
    "## Creating a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import scipp as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating an empty dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = sc.Dataset()\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `Dataset` as a table\n",
    "\n",
    "We can think about, and indeed use a dataset as a table.\n",
    "This will demonstrate the basic ways of creating datasets and interacting with them.\n",
    "Columns can be added one by one.\n",
    "We create a `scipp.Variable` using `array`, one of scipp's [creation functions](https://scipp.github.io/reference/creation-functions.html) and immediately insert it into the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['alice'] = sc.array(\n",
    "    dims=['row'], values=[1.0, 1.1, 1.2], variances=[0.01, 0.01, 0.02], unit='m'\n",
    ")\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the column for `'alice'` contains two sub-columns with values and associated variances (uncertainties).\n",
    "The uncertainties are optional.\n",
    "The datatype (`dtype`) is derived from the provided data, so passing `np.arange(3)` will yield a variable (column) containing 64-bit integers.\n",
    "\n",
    "As this dataset is 1-D we can visualize it as a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many practicle purposes we want to associate a set of values (optionally a unit) with our dimension.\n",
    "Let us introduce a coordinate for `row` so that we can assign a row number starting at zero.\n",
    "Coordinates, just like data columns, are variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.coords['row'] = sc.arange('row', 3, unit=None)\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the coordinate acts as a row header for the table.\n",
    "Coordinates have a purpose similar to Pandas' *index*, but they are more general.\n",
    "For example we can have multiple coordinates.\n",
    "\n",
    "More details of the dataset are visible in its HTML representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A data item (column) in a dataset (table) is identified by its name (`'alice'`).\n",
    "Note how each coordinate and data item is associated with a tuple of dimension labels and a shape tuple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds.coords['row'].dims)\n",
    "print(ds.coords['row'].shape)\n",
    "print(ds['alice'].dims)\n",
    "print(ds['alice'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to understand the difference between items in a dataset (`scipp.DataArray`, includes coordinates), the variable that holds the data of the item (`scipp.Variable`), and the actual values.\n",
    "The following illustrates the differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "display(sc.table(ds['alice']))  # data array, includes coordinates\n",
    "display(\n",
    "    sc.table(ds['alice'].data)\n",
    ")  # the variable holding the data, i.e., the dimension labels, units, values, and optional variances\n",
    "print(\n",
    "    \"values:\", ds['alice'].values\n",
    ")  # just the array of values, shorthand for d['alice'].data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset works very similar to a Python `dict`.\n",
    "For example we can insert new entries (here: columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['bob'] = ds['alice'].copy()  # make a deep copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `show()` function provides a quick graphical preview on the structure of a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.show(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations between columns are supported by indexing into a dataset with a name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['bob'] += ds['alice']\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the coordinate is unchanged by this operations.\n",
    "As a rule, operations *compare* coordinates (and fail if there is a mismatch).\n",
    "In this case the coordinates are guaranteed to be the same since we operate with two columns of the same dataset, but the same logic applies when using entries from different datasets.\n",
    "\n",
    "The contents of a dataset can be displayed on a graph using the `plot` method (or function):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot demonstrates the advantage of \"labeled\" data, provided by a dataset:\n",
    "Axes are automatically labeled and multiple items identified by their name are plotted.\n",
    "Furthermore, scipp's support for units and uncertainties means that all relevant information is directly included in a default plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operations between rows are supported by indexing into a dataset with a dimension label and an index.\n",
    "\n",
    "Slicing dimensions behaves similar to `numpy`:\n",
    "If a single index is given, the dimension is dropped, if a range is given, the dimension is kept.\n",
    "For a dataset, in the former case the corresponding coordinates are turned into attributes, whereas in the latter case the coordinate is preserved.\n",
    "Compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['row', 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['row', 1:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes are stored in a dictionary similar to coordinates.\n",
    "The difference is that attributes are not required to match in operations.\n",
    "Therefore we can perform the following operation without resulting in a error about a coordinate mismatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['row', 1] += ds['row', 2]\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the key advantage over `numpy` or `MATLAB`:\n",
    "We specify the index dimension, so we always know which dimension we are slicing.\n",
    "The advantage is not so apparent in 1-D, but will become clear once we move to higher-dimensional data.\n",
    "\n",
    "### Summary\n",
    "\n",
    "There is a number of ways to select and operate on a single row, a range of rows, a single variable (column) or multiple variables (columns) of a dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Single row\n",
    "display(sc.table(ds['row', 0:1]))\n",
    "# Range of rows\n",
    "display(sc.table(ds['row', 1:3]))\n",
    "# Single column (column pair if variance is present) including coordinate columns\n",
    "display(sc.table(ds[\"alice\"]))\n",
    "# Single variable (column pair if variance is present)\n",
    "display(sc.table(ds[\"alice\"].data))\n",
    "# Column values without header\n",
    "print(\"values:\", ds[\"alice\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "1. Combining row slicing and \"column\" indexing, add the last row of the data for `'alice'` to the first row of data for `'bob'`.\n",
    "2. Using the slice-range notation `a:b`, try adding the last two rows to the first two rows. Why does this fail?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['bob']['row', 0] += ds['alice']['row', -1]\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a range is given when slicing, the corresponding coordinate is preserved, and operations between misaligned data is prevented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "ds['bob']['row', 0:2] += ds['alice']['row', 1:3]  # will raise an exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To circumvent the safety catch we can operate on the underlying variables containing the data.\n",
    "The data is accessed using the `data` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['bob']['row', 0:2].data += ds['alice']['row', 1:3].data\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The slicing notation for variables (columns) and rows does not return a copy, but a view object.\n",
    "This is very similar to how `numpy` operates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_slice = a[0:3]\n",
    "a_slice += 100\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the slicing notation, create a new table (or replace the existing dataset `ds`) by one that does not contain the first and last row of `ds`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2 = ds['row', 1:-1].copy()\n",
    "\n",
    "# Or:\n",
    "# from copy import copy\n",
    "# table = copy(ds['row', 1:-1])\n",
    "\n",
    "sc.table(ds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the call to `copy()` is essential.\n",
    "If it is omitted we simply have a view onto the same data, and the orignal data is modified if the view is modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "just_a_view = ds['row', 1:-1]\n",
    "sc.to_html(just_a_view)\n",
    "just_a_view['alice'].values[0] = 666\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appending rows and columns\n",
    "We can append rows using `concat`, and add columns using `merge`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = sc.concat([ds['row', 0:3], ds['row', 1:3]], 'row')\n",
    "\n",
    "eve = sc.Dataset(data={'eve': sc.arange('row', 5.0)})\n",
    "ds = sc.merge(ds, eve)\n",
    "\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "Add the sum of the data for `alice` and `bob` as a new variable (column) to the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['sum'] = ds['alice'] + ds['bob']\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with `numpy` and scalars\n",
    "\n",
    "Values (or variances) in a dataset are exposed in a `numpy`-compatible buffer format.\n",
    "Direct access to the `numpy`-like underlying data array is possible using the `values` and `variances` properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['eve'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['alice'].variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly hand the buffers to `numpy` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['eve'].values = np.exp(ds['eve'].values)\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "1. As above for `np.exp` applied to the data for Eve, apply a `numpy` function to the data for Alice.\n",
    "2. What happens to the unit and uncertanties when modifying data with external code such as `numpy`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['alice'].values = np.sin(ds['alice'].values)\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy operations are not aware of the unit and uncertainties. Therefore the result is \"garbage\", unless the user has ensured herself that units and uncertainties are handled manually.\n",
    "\n",
    "Corollary: Whenever available, built-in operators and functions should be preferred over the use of `numpy`: these will handle units and uncertanties for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "1. Try adding a scalar value such as `1.5` to the `values` for `'eve'` or and `'alice'`.\n",
    "2. Try the same using the `data` property, instead of the `values` property.\n",
    "   Why is it not working for `'alice'`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['eve'].values += 1.5\n",
    "ds['alice'].values += 1.5\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of `values` we can use the `data` property.\n",
    "This will also correctly deal with variances, if applicable, whereas the direction operation with `values` is unaware of the presence of variances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['eve'].data += 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `data` for Alice has a unit, so a direct addition with a dimensionless quantity fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "ds['alice'].data += 1.5  # will raise an exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `Variable` to provide a scalar quantity with attached unit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "scale = sc.scalar(1.5, unit='m**2')\n",
    "ds['alice'].data += scale\n",
    "sc.table(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to [Multi-dimensional datasets](multi-d-datasets.ipynb) to see how datasets are used with multi-dimensional data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
